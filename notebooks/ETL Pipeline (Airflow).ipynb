{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36445644",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook will connect to Redshift (IaC) using Spark and JDBC driver and put everything together by building an ETL pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e4a1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.operators.dummy import DummyOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a438a8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../config.cfg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get config object from config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../config.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec602a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve access key and secret key\n",
    "aws_access_key_id = config['AWS']['aws_access_key_id']\n",
    "aws_secret_access_key = config['AWS']['aws_secret_access_key']\n",
    "\n",
    "role_arn = config['Redshift']['role_arn']\n",
    "region_name = config['Redshift']['region']\n",
    "bucket_name = config['S3']['bucket_name']\n",
    "region_name = config['Redshift']['region']\n",
    "\n",
    "user_name = config['Redshift']['user_name']\n",
    "password = config['Redshift']['password']\n",
    "host = config['Redshift']['host']\n",
    "port = config['Redshift']['port']\n",
    "schema = config['Redshift']['schema']\n",
    "database = config['Redshift']['database']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f711e842",
   "metadata": {},
   "source": [
    "## Put it all together - Build an ETL pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bfbffa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mstandalone\u001b[0m | Starting Airflow Standalone\n",
      "\u001b[37mstandalone\u001b[0m | Checking database is initialized\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "WARNI [airflow.models.crypto] empty cryptography key - values will not be stored encrypted.\n",
      "ERROR [root] Failed to execute 'udac_example_dag' DAG\n",
      "WARNI [unusual_prefix_daf6bd5d8d86e554f15a2b38f848b0c451715405_example_kubernetes_executor_config] Could not import DAGs in example_kubernetes_executor_config.py: No module named 'kubernetes'\n",
      "WARNI [unusual_prefix_daf6bd5d8d86e554f15a2b38f848b0c451715405_example_kubernetes_executor_config] Install kubernetes dependencies with: pip install apache-airflow['cncf.kubernetes']\n",
      "\u001b[37mstandalone\u001b[0m | Database ready\n",
      "[\u001b[34m2021-11-26 17:37:44,206\u001b[0m] {\u001b[34mmanager.py:\u001b[0m512} \u001b[33mWARNING\u001b[0m - \u001b[33mRefused to delete permission view, assoc with role exists DAG Runs.can_create Admin\u001b[0m\n",
      "\u001b[1;33m/Users/ngodylan/opt/anaconda3/lib/python3.8/site-packages/airflow/\u001b[0m\u001b[1;33mplugins_manager.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m245\u001b[0m\u001b[1;33m DeprecationWarning\u001b[0m\u001b[33m: This decorator is deprecated.\u001b[0m\n",
      "\n",
      "\u001b[33mIn previous versions, all subclasses of BaseOperator must use apply_default decorator for the `default_args` feature to work properly.\u001b[0m\n",
      "\n",
      "\u001b[33mIn current version, it is optional. The decorator is applied automatically using the metaclass.\u001b[0m\n",
      "\n",
      "\u001b[36m triggerer\u001b[0m | ____________       _____________\n",
      "\u001b[36m triggerer\u001b[0m | ____    |__( )_________  __/__  /________      __\n",
      "\u001b[36m triggerer\u001b[0m | ____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
      "\u001b[36m triggerer\u001b[0m | ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
      "\u001b[36m triggerer\u001b[0m | _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
      "\u001b[36m triggerer\u001b[0m | [\u001b[34m2021-11-26 17:37:47,960\u001b[0m] {\u001b[34mtriggerer_job.py:\u001b[0m101} INFO\u001b[0m - Starting the triggerer\u001b[0m\n",
      "\u001b[34m scheduler\u001b[0m | ____________       _____________\n",
      "\u001b[34m scheduler\u001b[0m | ____    |__( )_________  __/__  /________      __\n",
      "\u001b[34m scheduler\u001b[0m | ____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
      "\u001b[34m scheduler\u001b[0m | ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
      "\u001b[34m scheduler\u001b[0m | _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
      "\u001b[34m scheduler\u001b[0m | [\u001b[34m2021-11-26 17:37:47,987\u001b[0m] {\u001b[34mscheduler_job.py:\u001b[0m596} INFO\u001b[0m - Starting the scheduler\u001b[0m\n",
      "\u001b[34m scheduler\u001b[0m | [\u001b[34m2021-11-26 17:37:47,988\u001b[0m] {\u001b[34mscheduler_job.py:\u001b[0m601} INFO\u001b[0m - Processing each file at most -1 times\u001b[0m\n",
      "\u001b[34m scheduler\u001b[0m | [\u001b[34m2021-11-26 17:37:47,996\u001b[0m] {\u001b[34mmanager.py:\u001b[0m163} INFO\u001b[0m - Launched DagFileProcessorManager with pid: 29602\u001b[0m\n",
      "\u001b[34m scheduler\u001b[0m | [\u001b[34m2021-11-26 17:37:47,997\u001b[0m] {\u001b[34mscheduler_job.py:\u001b[0m1114} INFO\u001b[0m - Resetting orphaned tasks for active dag runs\u001b[0m\n",
      "\u001b[32m webserver\u001b[0m | ____________       _____________\n",
      "\u001b[32m webserver\u001b[0m | ____    |__( )_________  __/__  /________      __\n",
      "\u001b[32m webserver\u001b[0m | ____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
      "\u001b[32m webserver\u001b[0m | ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
      "\u001b[32m webserver\u001b[0m | _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
      "\u001b[32m webserver\u001b[0m | [\u001b[34m2021-11-26 17:37:48,765\u001b[0m] {\u001b[34mdagbag.py:\u001b[0m500} INFO\u001b[0m - Filling up the DagBag from /dev/null\u001b[0m\n",
      "\u001b[32m webserver\u001b[0m | [\u001b[34m2021-11-26 17:37:49,088\u001b[0m] {\u001b[34mmanager.py:\u001b[0m512} WARNING\u001b[0m - Refused to delete permission view, assoc with role exists DAG Runs.can_create Admin\u001b[0m\n",
      "\u001b[32m webserver\u001b[0m | /Users/ngodylan/opt/anaconda3/lib/python3.8/site-packages/airflow/plugins_manager.py:245 DeprecationWarning: This decorator is deprecated.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[32m webserver\u001b[0m | In previous versions, all subclasses of BaseOperator must use apply_default decorator for the `default_args` feature to work properly.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[32m webserver\u001b[0m | In current version, it is optional. The decorator is applied automatically using the metaclass.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[34m scheduler\u001b[0m | [2021-11-26 17:37:49 -0600] [29601] [INFO] Starting gunicorn 20.1.0\n",
      "\u001b[34m scheduler\u001b[0m | [2021-11-26 17:37:49 -0600] [29601] [INFO] Listening at: http://0.0.0.0:8793 (29601)\n",
      "\u001b[34m scheduler\u001b[0m | [2021-11-26 17:37:49 -0600] [29601] [INFO] Using worker: sync\n",
      "\u001b[34m scheduler\u001b[0m | [2021-11-26 17:37:49 -0600] [29607] [INFO] Booting worker with pid: 29607\n",
      "\u001b[34m scheduler\u001b[0m | [2021-11-26 17:37:49 -0600] [29608] [INFO] Booting worker with pid: 29608\n",
      "\u001b[34m scheduler\u001b[0m | [\u001b[34m2021-11-26 17:37:49,657\u001b[0m] {\u001b[34msettings.py:\u001b[0m52} INFO\u001b[0m - Configured default timezone Timezone('UTC')\u001b[0m\n",
      "\u001b[34m scheduler\u001b[0m | [2021-11-26 17:37:49,661] {manager.py:431} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2 ) when using sqlite. So we set parallelism to 1.\n",
      "\u001b[32m webserver\u001b[0m | [2021-11-26 17:37:51 -0600] [29612] [INFO] Starting gunicorn 20.1.0\n",
      "\u001b[32m webserver\u001b[0m | [2021-11-26 17:37:51 -0600] [29612] [INFO] Listening at: http://0.0.0.0:8080 (29612)\n",
      "\u001b[32m webserver\u001b[0m | [2021-11-26 17:37:51 -0600] [29612] [INFO] Using worker: sync\n",
      "\u001b[32m webserver\u001b[0m | [2021-11-26 17:37:51 -0600] [29616] [INFO] Booting worker with pid: 29616\n",
      "\u001b[32m webserver\u001b[0m | [2021-11-26 17:37:51 -0600] [29617] [INFO] Booting worker with pid: 29617\n",
      "\u001b[32m webserver\u001b[0m | [2021-11-26 17:37:51 -0600] [29618] [INFO] Booting worker with pid: 29618\n",
      "\u001b[32m webserver\u001b[0m | [2021-11-26 17:37:52 -0600] [29619] [INFO] Booting worker with pid: 29619\n",
      "\u001b[32m webserver\u001b[0m | [\u001b[34m2021-11-26 17:37:53,455\u001b[0m] {\u001b[34mmanager.py:\u001b[0m512} WARNING\u001b[0m - Refused to delete permission view, assoc with role exists DAG Runs.can_create Admin\u001b[0m\n",
      "\u001b[32m webserver\u001b[0m | [\u001b[34m2021-11-26 17:37:53,475\u001b[0m] {\u001b[34mmanager.py:\u001b[0m512} WARNING\u001b[0m - Refused to delete permission view, assoc with role exists DAG Runs.can_create Admin\u001b[0m\n",
      "\u001b[32m webserver\u001b[0m | [\u001b[34m2021-11-26 17:37:53,569\u001b[0m] {\u001b[34mmanager.py:\u001b[0m512} WARNING\u001b[0m - Refused to delete permission view, assoc with role exists DAG Runs.can_create Admin\u001b[0m\n",
      "\u001b[32m webserver\u001b[0m | [\u001b[34m2021-11-26 17:37:53,670\u001b[0m] {\u001b[34mmanager.py:\u001b[0m512} WARNING\u001b[0m - Refused to delete permission view, assoc with role exists DAG Runs.can_create Admin\u001b[0m\n",
      "\u001b[32m webserver\u001b[0m | /Users/ngodylan/opt/anaconda3/lib/python3.8/site-packages/airflow/plugins_manager.py:245 DeprecationWarning: This decorator is deprecated.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[32m webserver\u001b[0m | In previous versions, all subclasses of BaseOperator must use apply_default decorator for the `default_args` feature to work properly.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[32m webserver\u001b[0m | In current version, it is optional. The decorator is applied automatically using the metaclass.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[32m webserver\u001b[0m | /Users/ngodylan/opt/anaconda3/lib/python3.8/site-packages/airflow/plugins_manager.py:245 DeprecationWarning: This decorator is deprecated.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[32m webserver\u001b[0m | In previous versions, all subclasses of BaseOperator must use apply_default decorator for the `default_args` feature to work properly.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[32m webserver\u001b[0m | In current version, it is optional. The decorator is applied automatically using the metaclass.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[32m webserver\u001b[0m | /Users/ngodylan/opt/anaconda3/lib/python3.8/site-packages/airflow/plugins_manager.py:245 DeprecationWarning: This decorator is deprecated.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[32m webserver\u001b[0m | In previous versions, all subclasses of BaseOperator must use apply_default decorator for the `default_args` feature to work properly.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[32m webserver\u001b[0m | In current version, it is optional. The decorator is applied automatically using the metaclass.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[32m webserver\u001b[0m | /Users/ngodylan/opt/anaconda3/lib/python3.8/site-packages/airflow/plugins_manager.py:245 DeprecationWarning: This decorator is deprecated.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[32m webserver\u001b[0m | In previous versions, all subclasses of BaseOperator must use apply_default decorator for the `default_args` feature to work properly.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[32m webserver\u001b[0m | In current version, it is optional. The decorator is applied automatically using the metaclass.\n",
      "\u001b[32m webserver\u001b[0m | \n",
      "\u001b[37mstandalone\u001b[0m | \n",
      "\u001b[37mstandalone\u001b[0m | Airflow is ready\n",
      "\u001b[37mstandalone\u001b[0m | Login with username: admin  password: hpS2bSQ7uT8WSzqQ\n",
      "\u001b[37mstandalone\u001b[0m | Airflow Standalone is for development purposes only. Do not use this in production!\n",
      "\u001b[37mstandalone\u001b[0m | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m webserver\u001b[0m | 127.0.0.1 - - [26/Nov/2021:17:38:03 -0600] \"GET /home HTTP/1.1\" 200 27586 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.55 Safari/537.36\"\n",
      "\u001b[32m webserver\u001b[0m | 127.0.0.1 - - [26/Nov/2021:17:38:03 -0600] \"GET /static/pin_32.png HTTP/1.1\" 304 0 \"http://localhost:8080/home\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.55 Safari/537.36\"\n",
      "\u001b[36m triggerer\u001b[0m | [\u001b[34m2021-11-26 17:38:48,079\u001b[0m] {\u001b[34mtriggerer_job.py:\u001b[0m251} INFO\u001b[0m - 0 triggers currently running\u001b[0m\n",
      "\u001b[36m triggerer\u001b[0m | [\u001b[34m2021-11-26 17:39:48,181\u001b[0m] {\u001b[34mtriggerer_job.py:\u001b[0m251} INFO\u001b[0m - 0 triggers currently running\u001b[0m\n",
      "\u001b[36m triggerer\u001b[0m | [\u001b[34m2021-11-26 17:40:48,342\u001b[0m] {\u001b[34mtriggerer_job.py:\u001b[0m251} INFO\u001b[0m - 0 triggers currently running\u001b[0m\n",
      "\u001b[36m triggerer\u001b[0m | [\u001b[34m2021-11-26 17:41:48,471\u001b[0m] {\u001b[34mtriggerer_job.py:\u001b[0m251} INFO\u001b[0m - 0 triggers currently running\u001b[0m\n",
      "\u001b[36m triggerer\u001b[0m | [\u001b[34m2021-11-26 17:42:48,590\u001b[0m] {\u001b[34mtriggerer_job.py:\u001b[0m251} INFO\u001b[0m - 0 triggers currently running\u001b[0m\n",
      "\u001b[34m scheduler\u001b[0m | [\u001b[34m2021-11-26 17:42:49,758\u001b[0m] {\u001b[34mscheduler_job.py:\u001b[0m1114} INFO\u001b[0m - Resetting orphaned tasks for active dag runs\u001b[0m\n",
      "\u001b[34m scheduler\u001b[0m | [\u001b[34m2021-11-26 17:42:49,760\u001b[0m] {\u001b[34mscheduler_job.py:\u001b[0m1137} INFO\u001b[0m - Marked 1 SchedulerJob instances as failed\u001b[0m\n",
      "\u001b[36m triggerer\u001b[0m | [\u001b[34m2021-11-26 17:43:48,732\u001b[0m] {\u001b[34mtriggerer_job.py:\u001b[0m251} INFO\u001b[0m - 0 triggers currently running\u001b[0m\n",
      "^C\n",
      "\u001b[37mstandalone\u001b[0m | Shutting down components\n"
     ]
    }
   ],
   "source": [
    "# start an Airflow session\n",
    "!airflow standalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34b0bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add default arguments\n",
    "default_args = {\n",
    "    'owner': 'udacity',\n",
    "    'start_date': datetime(2019, 1, 12),\n",
    "    'depends_on_past': False,\n",
    "    'email_on_retry': False,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    'catchup': False,\n",
    "    'on_failure_callback': logging.error(\"Failed to execute 'udac_example_dag' DAG\")\n",
    "}\n",
    "\n",
    "# create the main DAG\n",
    "dag = DAG('nyse-stock',\n",
    "          default_args=default_args,\n",
    "          description='an end-to-end ETL Pipeline from feching API to S3 to Redshift',\n",
    "          schedule_interval='0 * * * *'\n",
    "        )\n",
    "\n",
    "# create a dummy operator\n",
    "start_operator = DummyOperator(task_id='Begin_execution',  dag=dag)\n",
    "\n",
    "# fetch stock data from RapidAPI\n",
    "fetch_stock_data_task = PythonOperator(\n",
    "    task_id = \"fetch_stock_data_task\",\n",
    "    dag = dag,\n",
    "    python_callable = fetch_stock_data\n",
    ")\n",
    "\n",
    "# process indicators table\n",
    "process_indicators_table_task = PythonOperator(\n",
    "    task_id = \"process_indicators_table_task\",\n",
    "    dag = dag,\n",
    "    python_callable = process_indicators_table\n",
    ")\n",
    "\n",
    "# process metadata table\n",
    "process_metadata_table_task = PythonOperator(\n",
    "    task_id = \"process_metadata_table_task\",\n",
    "    dag = dag,\n",
    "    python_callable = process_metadata_table \n",
    ")\n",
    "\n",
    "# upload indicators table to S3\n",
    "upload_indicators_to_S3_task = PythonOperator(\n",
    "    task_id = \"upload_indicators_S3_task\",\n",
    "    dag = dag,\n",
    "    python_callable = pload_indicators_to_S3\n",
    ")\n",
    "\n",
    "# upload metadata table to S3\n",
    "upload_metadata_to_S3_task = PythonOperator(\n",
    "    task_id = \"upload_metadata_S3_task\",\n",
    "    dag = dag,\n",
    "    python_callable = upload_metadata_to_S3\n",
    ")\n",
    "\n",
    "# migrate S3 to redshift\n",
    "migrate_S3_to_redshift_task = PythonOperator(\n",
    "    task_id = \"migrate_S3_to_redshift_task\",\n",
    "    dag = dag,\n",
    "    python_callable = migrate_S3_to_redshift\n",
    ")\n",
    "\n",
    "# include data quality\n",
    "data_quality_check_task = PythonOperator(\n",
    "    task_id = \"data_quality_check_task\",\n",
    "    dag = dag,\n",
    "    python_callable = data_quality_check\n",
    ")\n",
    "\n",
    "# create a dummy operator\n",
    "end_operator = DummyOperator(task_id='Stop_execution',  dag=dag)\n",
    "\n",
    "# Add the dependencies\n",
    "start_operator >> fetch_stock_data_task\n",
    "fetch_stock_data_task >> [process_indicators_table_task, process_metadata_table_task]\n",
    "process_indicators_table_task >> upload_indicators_to_S3_task\n",
    "process_metadata_table_task >> upload_metadata_to_S3_task\n",
    "[upload_indicators_to_S3_task, upload_metadata_to_S3_task] >> migrate_S3_to_redshift_task\n",
    "migrate_S3_to_redshift_task >> data_quality_check_task\n",
    "data_quality_check_task >> end_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4dd0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
